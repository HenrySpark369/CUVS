{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30970ca3",
   "metadata": {},
   "source": [
    "# Análisis Profundo del Proyecto CUVS: Introducción y Uso Básico\n",
    "\n",
    "Este notebook proporciona una introducción profunda al proyecto CUVS de RAPIDS, una biblioteca para búsqueda de vectores y clustering acelerada por GPU. Cubriremos instalación, uso básico y pruebas de utilidad y rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c371768b",
   "metadata": {},
   "source": [
    "## 1. Instalar RAPIDS y CUVS\n",
    "\n",
    "CUVS es parte de RAPIDS, un suite de bibliotecas para data science acelerada por GPU. Para instalar en Google Colab o un entorno Jupyter, usa pip con soporte CUDA.\n",
    "\n",
    "Nota: Asegúrate de tener una GPU NVIDIA compatible. En Colab, selecciona Runtime > Change runtime type > GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7eb013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar RAPIDS y CUVS\n",
    "# Para CUDA 12 (común en Colab)\n",
    "!pip install cuvs-cu12 --extra-index-url=https://pypi.nvidia.com\n",
    "\n",
    "# O para CUDA 11\n",
    "# !pip install cuvs-cu11 --extra-index-url=https://pypi.nvidia.com\n",
    "\n",
    "# Verificar instalación\n",
    "import cuvs\n",
    "print(\"CUVS versión:\", cuvs.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711cd4d2",
   "metadata": {},
   "source": [
    "## 2. Importar Librerías Requeridas\n",
    "\n",
    "Importamos las librerías necesarias, incluyendo cuVS para operaciones vectoriales, NumPy para arrays, y otras para manejo de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1156b32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "from cuvs.common import Resources\n",
    "from cuvs.neighbors import ivf_flat\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86091d17",
   "metadata": {},
   "source": [
    "## 3. Cargar y Preparar Dataset\n",
    "\n",
    "Cargamos un dataset de ejemplo, como vectores de embeddings. Usaremos datos sintéticos o de sklearn para simplicidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef46844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar datos sintéticos: 10000 vectores de 128 dimensiones\n",
    "np.random.seed(42)\n",
    "n_samples = 10000\n",
    "dim = 128\n",
    "dataset = np.random.randn(n_samples, dim).astype(np.float32)\n",
    "\n",
    "# Normalizar para similitud coseno\n",
    "dataset = dataset / np.linalg.norm(dataset, axis=1, keepdims=True)\n",
    "\n",
    "# Queries: 100 vectores aleatorios\n",
    "n_queries = 100\n",
    "queries = np.random.randn(n_queries, dim).astype(np.float32)\n",
    "queries = queries / np.linalg.norm(queries, axis=1, keepdims=True)\n",
    "\n",
    "print(f\"Dataset shape: {dataset.shape}\")\n",
    "print(f\"Queries shape: {queries.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2addc4ea",
   "metadata": {},
   "source": [
    "## 4. Construir Índice CUVS\n",
    "\n",
    "Creamos un índice usando IVF-Flat, un algoritmo eficiente para búsqueda aproximada de vecinos más cercanos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d84bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resources = Resources()\n",
    "\n",
    "# Parámetros de construcción\n",
    "build_params = ivf_flat.IndexParams(\n",
    "    n_lists=1024,  # Número de clusters\n",
    "    metric=\"cosine\",  # Métrica de distancia\n",
    "    add_data_on_build=True\n",
    ")\n",
    "\n",
    "# Construir índice\n",
    "start_time = time.time()\n",
    "index = ivf_flat.build(build_params, cp.asarray(dataset), resources=resources)\n",
    "resources.sync()\n",
    "build_time = time.time() - start_time\n",
    "\n",
    "print(f\"Índice construido en {build_time:.2f} segundos\")\n",
    "print(f\"Índice: {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7489903d",
   "metadata": {},
   "source": [
    "## 5. Realizar Búsqueda de Vectores\n",
    "\n",
    "Ejecutamos búsquedas de similitud en el índice construido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba83a2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros de búsqueda\n",
    "search_params = ivf_flat.SearchParams(n_probes=10)  # Número de clusters a buscar\n",
    "k = 10  # Top-k vecinos\n",
    "\n",
    "# Búsqueda\n",
    "start_time = time.time()\n",
    "distances, neighbors = ivf_flat.search(\n",
    "    search_params, \n",
    "    index, \n",
    "    cp.asarray(queries), \n",
    "    k=k, \n",
    "    resources=resources\n",
    ")\n",
    "resources.sync()\n",
    "search_time = time.time() - start_time\n",
    "\n",
    "print(f\"Búsqueda completada en {search_time:.4f} segundos\")\n",
    "print(f\"Tiempo por query: {search_time / n_queries * 1000:.2f} ms\")\n",
    "print(f\"Distances shape: {distances.shape}\")\n",
    "print(f\"Neighbors shape: {neighbors.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dd94ec",
   "metadata": {},
   "source": [
    "## 6. Evaluar Precisión de Búsqueda\n",
    "\n",
    "Calculamos métricas como recall comparando con resultados exactos (usando brute force)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaee649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular distancias exactas usando brute force\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "exact_distances = cosine_distances(queries, dataset)\n",
    "exact_neighbors = np.argsort(exact_distances, axis=1)[:, :k]\n",
    "\n",
    "# Calcular recall\n",
    "def recall_at_k(pred, true, k):\n",
    "    recall = 0\n",
    "    for i in range(len(pred)):\n",
    "        recall += len(set(pred[i]) & set(true[i])) / k\n",
    "    return recall / len(pred)\n",
    "\n",
    "approx_neighbors = cp.asnumpy(neighbors)\n",
    "recall = recall_at_k(approx_neighbors, exact_neighbors, k)\n",
    "print(f\"Recall@{k}: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0357d798",
   "metadata": {},
   "source": [
    "## 7. Benchmark de Métricas de Rendimiento\n",
    "\n",
    "Medimos tiempos de construcción, búsqueda y uso de memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c65de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Tiempo de construcción del índice: {build_time:.2f} s\")\n",
    "print(f\"Tiempo total de búsqueda: {search_time:.4f} s\")\n",
    "print(f\"Queries por segundo (QPS): {n_queries / search_time:.2f}\")\n",
    "\n",
    "# Uso de memoria (aproximado)\n",
    "import psutil\n",
    "process = psutil.Process()\n",
    "mem_usage = process.memory_info().rss / (1024 ** 3)  # GB\n",
    "print(f\"Uso de memoria aproximado: {mem_usage:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d369614",
   "metadata": {},
   "source": [
    "## 8. Comparar con Alternativas Basadas en CPU\n",
    "\n",
    "Comparamos con FAISS en CPU para ver la aceleración GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec266df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar FAISS si no está\n",
    "!pip install faiss-cpu\n",
    "\n",
    "import faiss\n",
    "\n",
    "# Construir índice FAISS\n",
    "index_faiss = faiss.IndexFlatIP(dim)  # Producto interno para coseno\n",
    "index_faiss.add(dataset)\n",
    "\n",
    "# Búsqueda FAISS\n",
    "start_time_faiss = time.time()\n",
    "distances_faiss, neighbors_faiss = index_faiss.search(queries, k)\n",
    "search_time_faiss = time.time() - start_time_faiss\n",
    "\n",
    "print(f\"FAISS búsqueda tiempo: {search_time_faiss:.4f} s\")\n",
    "print(f\"CUVS búsqueda tiempo: {search_time:.4f} s\")\n",
    "print(f\"Aceleración: {search_time_faiss / search_time:.2f}x\")\n",
    "\n",
    "# Recall FAISS (exacto)\n",
    "recall_faiss = recall_at_k(neighbors_faiss, exact_neighbors, k)\n",
    "print(f\"Recall FAISS: {recall_faiss:.4f}\")\n",
    "print(f\"Recall CUVS: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf1784d",
   "metadata": {},
   "source": [
    "## 9. Optimizar Parámetros del Índice\n",
    "\n",
    "Experimentamos con diferentes parámetros como n_lists y n_probes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0dc57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimentar con n_probes\n",
    "n_probes_list = [1, 5, 10, 20, 50]\n",
    "recalls = []\n",
    "times = []\n",
    "\n",
    "for n_probes in n_probes_list:\n",
    "    search_params = ivf_flat.SearchParams(n_probes=n_probes)\n",
    "    start = time.time()\n",
    "    dist, neigh = ivf_flat.search(search_params, index, cp.asarray(queries), k=k, resources=resources)\n",
    "    resources.sync()\n",
    "    t = time.time() - start\n",
    "    r = recall_at_k(cp.asnumpy(neigh), exact_neighbors, k)\n",
    "    recalls.append(r)\n",
    "    times.append(t)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(n_probes_list, recalls, marker='o')\n",
    "plt.xlabel('n_probes')\n",
    "plt.ylabel('Recall@10')\n",
    "plt.title('Recall vs n_probes')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(n_probes_list, times, marker='o')\n",
    "plt.xlabel('n_probes')\n",
    "plt.ylabel('Tiempo de búsqueda (s)')\n",
    "plt.title('Tiempo vs n_probes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3b845e",
   "metadata": {},
   "source": [
    "## 10. Manejar Datasets a Gran Escala\n",
    "\n",
    "Demostramos escalado a datasets más grandes, manejando procesamiento por lotes y memoria GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d863a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para datasets grandes, procesar en lotes\n",
    "large_dataset = np.random.randn(50000, dim).astype(np.float32)\n",
    "large_dataset = large_dataset / np.linalg.norm(large_dataset, axis=1, keepdims=True)\n",
    "\n",
    "batch_size = 10000\n",
    "for i in range(0, len(large_dataset), batch_size):\n",
    "    batch = large_dataset[i:i+batch_size]\n",
    "    # Extender índice con batch\n",
    "    ivf_flat.extend(index, cp.asarray(batch), cp.arange(i, i+len(batch), dtype=cp.int64))\n",
    "    resources.sync()\n",
    "\n",
    "print(\"Índice extendido con datos adicionales\")\n",
    "\n",
    "# Búsqueda en índice grande\n",
    "distances_large, neighbors_large = ivf_flat.search(\n",
    "    search_params, index, cp.asarray(queries), k=k, resources=resources\n",
    ")\n",
    "resources.sync()\n",
    "print(f\"Búsqueda en dataset grande completada\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
